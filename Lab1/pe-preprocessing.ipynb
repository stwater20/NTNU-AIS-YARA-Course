{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pefile\n",
      "  Downloading pefile-2024.8.26-py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading pefile-2024.8.26-py3-none-any.whl (74 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.8/74.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pefile\n",
      "Successfully installed pefile-2024.8.26\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n",
      "\t -> Bad PE format\n",
      "1a12978b7cb380549b52352572f1ec4b9ad3b96d8e1b871aa397423c05e4df09\n",
      "0e884fdc7efa4be063a6e9a8bac982a2e36af1fc576b3f24533119bbb76dd740\n",
      "2b9e07e356095c13dc5dede21f931385abcaca14ae5e5092ec69e1e93fb4269e\n",
      "calc.exe\n",
      ".DS_Store\n",
      "\t -> Bad PE format\n",
      "4d29858f66a33c48e0a1fc04c12d43a6a4b79f43003c2dbd3d8c72378af4855b\n",
      "0b9397a5316123179d30cfe988b310e27df1d7562d612150748531dd3ec771fc\n",
      "4b211c73a205eb3da49c4f327ad317934f2cb99daabd99bf772857812283a2a9\n",
      "3a8dd0a8891d7296ea7aef2b4508d6ffb5eeca3690e8d9a882ba85057787e323\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import hashlib\n",
    "import array\n",
    "import math\n",
    "import pefile\n",
    "import pandas as pd\n",
    "\n",
    "def get_md5(fname):\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(fname, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "def get_entropy(data):\n",
    "    if len(data) == 0:\n",
    "        return 0.0\n",
    "    occurrences = array.array('L', [0] * 256)\n",
    "    for x in data:\n",
    "        occurrences[x if isinstance(x, int) else ord(x)] += 1\n",
    "\n",
    "    entropy = 0\n",
    "    for x in occurrences:\n",
    "        if x:\n",
    "            p_x = float(x) / len(data)\n",
    "            entropy -= p_x * math.log(p_x, 2)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "def get_resources(pe):\n",
    "    \"\"\"Extract resources :\n",
    "    [entropy, size]\"\"\"\n",
    "    resources = []\n",
    "    if hasattr(pe, 'DIRECTORY_ENTRY_RESOURCE'):\n",
    "        try:\n",
    "            for resource_type in pe.DIRECTORY_ENTRY_RESOURCE.entries:\n",
    "                if hasattr(resource_type, 'directory'):\n",
    "                    for resource_id in resource_type.directory.entries:\n",
    "                        if hasattr(resource_id, 'directory'):\n",
    "                            for resource_lang in resource_id.directory.entries:\n",
    "                                data = pe.get_data(resource_lang.data.struct.OffsetToData,\n",
    "                                                   resource_lang.data.struct.Size)\n",
    "                                size = resource_lang.data.struct.Size\n",
    "                                entropy = get_entropy(data)\n",
    "\n",
    "                                resources.append([entropy, size])\n",
    "        except Exception as e:\n",
    "            return resources\n",
    "    return resources\n",
    "\n",
    "def get_version_info(pe):\n",
    "    \"\"\"Return version infos\"\"\"\n",
    "    res = {}\n",
    "    for fileinfo in pe.FileInfo:\n",
    "        if fileinfo.Key == 'StringFileInfo':\n",
    "            for st in fileinfo.StringTable:\n",
    "                for entry in st.entries.items():\n",
    "                    res[entry[0]] = entry[1]\n",
    "        if fileinfo.Key == 'VarFileInfo':\n",
    "            for var in fileinfo.Var:\n",
    "                res[var.entry.items()[0][0]] = var.entry.items()[0][1]\n",
    "    if hasattr(pe, 'VS_FIXEDFILEINFO'):\n",
    "        res['flags'] = pe.VS_FIXEDFILEINFO.FileFlags\n",
    "        res['os'] = pe.VS_FIXEDFILEINFO.FileOS\n",
    "        res['type'] = pe.VS_FIXEDFILEINFO.FileType\n",
    "        res['file_version'] = pe.VS_FIXEDFILEINFO.FileVersionLS\n",
    "        res['product_version'] = pe.VS_FIXEDFILEINFO.ProductVersionLS\n",
    "        res['signature'] = pe.VS_FIXEDFILEINFO.Signature\n",
    "        res['struct_version'] = pe.VS_FIXEDFILEINFO.StrucVersion\n",
    "    return res\n",
    "\n",
    "def extract_infos(fpath):\n",
    "    res = []\n",
    "    res.append(os.path.basename(fpath))\n",
    "    res.append(get_md5(fpath))\n",
    "    pe = pefile.PE(fpath)\n",
    "    res.append(pe.FILE_HEADER.Machine)\n",
    "    res.append(pe.FILE_HEADER.SizeOfOptionalHeader)\n",
    "    res.append(pe.FILE_HEADER.Characteristics)\n",
    "    res.append(pe.OPTIONAL_HEADER.MajorLinkerVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.MinorLinkerVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfCode)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfInitializedData)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfUninitializedData)\n",
    "    res.append(pe.OPTIONAL_HEADER.AddressOfEntryPoint)\n",
    "    res.append(pe.OPTIONAL_HEADER.BaseOfCode)\n",
    "    try:\n",
    "        res.append(pe.OPTIONAL_HEADER.BaseOfData)\n",
    "    except AttributeError:\n",
    "        res.append(0)\n",
    "    res.append(pe.OPTIONAL_HEADER.ImageBase)\n",
    "    res.append(pe.OPTIONAL_HEADER.SectionAlignment)\n",
    "    res.append(pe.OPTIONAL_HEADER.FileAlignment)\n",
    "    res.append(pe.OPTIONAL_HEADER.MajorOperatingSystemVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.MinorOperatingSystemVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.MajorImageVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.MinorImageVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.MajorSubsystemVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.MinorSubsystemVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfImage)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfHeaders)\n",
    "    res.append(pe.OPTIONAL_HEADER.CheckSum)\n",
    "    res.append(pe.OPTIONAL_HEADER.Subsystem)\n",
    "    res.append(pe.OPTIONAL_HEADER.DllCharacteristics)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfStackReserve)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfStackCommit)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfHeapReserve)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfHeapCommit)\n",
    "    res.append(pe.OPTIONAL_HEADER.LoaderFlags)\n",
    "    res.append(pe.OPTIONAL_HEADER.NumberOfRvaAndSizes)\n",
    "    res.append(len(pe.sections))\n",
    "    entropy = list(map(lambda x: x.get_entropy(), pe.sections))\n",
    "    res.append(sum(entropy) / float(len(entropy)))\n",
    "    res.append(min(entropy))\n",
    "    res.append(max(entropy))\n",
    "    raw_sizes = list(map(lambda x: x.SizeOfRawData, pe.sections))\n",
    "    res.append(sum(raw_sizes) / float(len(raw_sizes)))\n",
    "    res.append(min(raw_sizes))\n",
    "    res.append(max(raw_sizes))\n",
    "    virtual_sizes = list(map(lambda x: x.Misc_VirtualSize, pe.sections))\n",
    "    res.append(sum(virtual_sizes) / float(len(virtual_sizes)))\n",
    "    res.append(min(virtual_sizes))\n",
    "    res.append(max(virtual_sizes))\n",
    "    # Imports\n",
    "    try:\n",
    "        res.append(len(pe.DIRECTORY_ENTRY_IMPORT))\n",
    "        imports = sum([x.imports for x in pe.DIRECTORY_ENTRY_IMPORT], [])\n",
    "        res.append(len(imports))\n",
    "        res.append(len([x for x in imports if x.name is None]))\n",
    "    except AttributeError:\n",
    "        res.append(0)\n",
    "        res.append(0)\n",
    "        res.append(0)\n",
    "    # Exports\n",
    "    try:\n",
    "        res.append(len(pe.DIRECTORY_ENTRY_EXPORT.symbols))\n",
    "    except AttributeError:\n",
    "        # No export\n",
    "        res.append(0)\n",
    "    # Resources\n",
    "    resources = get_resources(pe)\n",
    "    res.append(len(resources))\n",
    "    if len(resources) > 0:\n",
    "        entropy = list(map(lambda x: x[0], resources))\n",
    "        res.append(sum(entropy) / float(len(entropy)))\n",
    "        res.append(min(entropy))\n",
    "        res.append(max(entropy))\n",
    "        sizes = list(map(lambda x: x[1], resources))\n",
    "        res.append(sum(sizes) / float(len(sizes)))\n",
    "        res.append(min(sizes))\n",
    "        res.append(max(sizes))\n",
    "    else:\n",
    "        res.append(0)\n",
    "        res.append(0)\n",
    "        res.append(0)\n",
    "        res.append(0)\n",
    "        res.append(0)\n",
    "        res.append(0)\n",
    "\n",
    "    # Load configuration size\n",
    "    try:\n",
    "        res.append(pe.DIRECTORY_ENTRY_LOAD_CONFIG.struct.Size)\n",
    "    except AttributeError:\n",
    "        res.append(0)\n",
    "\n",
    "    # Version configuration size\n",
    "    try:\n",
    "        version_infos = get_version_info(pe)\n",
    "        res.append(len(version_infos.keys()))\n",
    "    except AttributeError:\n",
    "        res.append(0)\n",
    "    return res\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    os.makedirs('dataset', exist_ok=True)\n",
    "    output = \"./dataset/data.csv\"\n",
    "    csv_delimiter = \"|\"\n",
    "    columns = [\n",
    "        \"Name\", \"md5\", \"Machine\", \"SizeOfOptionalHeader\", \"Characteristics\", \"MajorLinkerVersion\", \"MinorLinkerVersion\",\n",
    "        \"SizeOfCode\", \"SizeOfInitializedData\", \"SizeOfUninitializedData\", \"AddressOfEntryPoint\", \"BaseOfCode\", \"BaseOfData\",\n",
    "        \"ImageBase\", \"SectionAlignment\", \"FileAlignment\", \"MajorOperatingSystemVersion\", \"MinorOperatingSystemVersion\", \n",
    "        \"MajorImageVersion\", \"MinorImageVersion\", \"MajorSubsystemVersion\", \"MinorSubsystemVersion\", \"SizeOfImage\", \n",
    "        \"SizeOfHeaders\", \"CheckSum\", \"Subsystem\", \"DllCharacteristics\", \"SizeOfStackReserve\", \"SizeOfStackCommit\", \n",
    "        \"SizeOfHeapReserve\", \"SizeOfHeapCommit\", \"LoaderFlags\", \"NumberOfRvaAndSizes\", \"SectionsNb\", \"SectionsMeanEntropy\",\n",
    "        \"SectionsMinEntropy\", \"SectionsMaxEntropy\", \"SectionsMeanRawsize\", \"SectionsMinRawsize\", \"SectionMaxRawsize\",\n",
    "        \"SectionsMeanVirtualsize\", \"SectionsMinVirtualsize\", \"SectionMaxVirtualsize\", \"ImportsNbDLL\", \"ImportsNb\",\n",
    "        \"ImportsNbOrdinal\", \"ExportNb\", \"ResourcesNb\", \"ResourcesMeanEntropy\", \"ResourcesMinEntropy\", \"ResourcesMaxEntropy\", \n",
    "        \"ResourcesMeanSize\", \"ResourcesMinSize\", \"ResourcesMaxSize\", \"LoadConfigurationSize\", \"VersionInformationSize\", \"legitimate\"\n",
    "    ]\n",
    "\n",
    "    with open(output, \"a\") as ff:\n",
    "        ff.write(csv_delimiter.join(columns) + \"\\n\")\n",
    "\n",
    "        # Process legitimate files\n",
    "        for ffile in os.listdir('./dataset/legitimate'):\n",
    "            print(ffile)\n",
    "            try:\n",
    "                res = extract_infos(os.path.join('./dataset/legitimate', ffile))\n",
    "                res.append(1)\n",
    "                ff.write(csv_delimiter.join(map(str, res)) + \"\\n\")\n",
    "            except pefile.PEFormatError:\n",
    "                print('\\t -> Bad PE format')\n",
    "\n",
    "        # Process malicious files\n",
    "        for ffile in os.listdir('./dataset/malicious'):\n",
    "            print(ffile)\n",
    "            try:\n",
    "                res = extract_infos(os.path.join('./dataset/malicious', ffile))\n",
    "                res.append(0)\n",
    "                ff.write(csv_delimiter.join(map(str, res)) + \"\\n\")\n",
    "            except pefile.PEFormatError:\n",
    "                print('\\t -> Bad PE format')\n",
    "            except Exception as e:\n",
    "                print(f'\\t -> Weird error: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
